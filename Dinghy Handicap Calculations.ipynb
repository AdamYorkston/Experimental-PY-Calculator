{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating handicaps for WOBYC dinghy racing\n",
    "This notebook was originally created for Waveney and Oulton Broad Yacht Club to demonstrate the calculation of a personalised handicap for the Oulton Rater XX2, for use in club dinghy racing. The data for XX2 is used with permission, and all other personal data has been redacted to comply with GDPR.\n",
    "\n",
    "In a sailing race a boat's finish time $t$ is modified by the handicap $PY$ (also known as the PY number)  to give the corrected time $T_\\textrm{corrected} = \\frac{1000\\, T}{PY}$. Dinghies generally have values of around $PY \\approx 1000$, with larger handicaps corresponding to slower boats.\n",
    "\n",
    "To compute a personalised handicap for the boat 'XX2', we assume that in each race it should attain a corrected time equal to the median corrected time. This allows us to compute a personalised handicap for each race\n",
    "\\begin{equation}\n",
    "PY_r = \\frac{1000 \\, T_\\textrm{XX2}}{\\textrm{median}(T_\\textrm{corrected})}.\n",
    "\\end{equation}\n",
    "The value of $PY_r$ will vary significantly between races depending on the performance of 'XX2', but a good estimate of the true handicap can be obtained by taking the median of the personalised handicap of each individual race\n",
    "\\begin{equation}\n",
    "PY_\\textrm{XX2} \\approx \\textrm{median}(PY_r)\n",
    "\\end{equation}\n",
    "Note that the median is used here to ensure outliers do not skew the handicap; this will be discussed further on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the necessary Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of the code is to compute a handicap for Oulton Rater XX2, but the code has been generalised to allow for any competitor by changing the value of `target_sailnumber`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sailnumber = 'XX2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `anonymise` is used to redact personal data from a pandas `DataFrame` before displaying to comply with GDPR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymise(df):\n",
    "    df2 = df.copy()\n",
    "    for col in ['HelmName', 'CrewName', 'SailNo', 'Boat', 'Class', 'PY', 'Elapsed', 'Corrected']:\n",
    "        if col in df.columns:\n",
    "            df2[col] = 'redacted (' + type(df2[col].iloc[0]).__name__ + ')'\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to want to download some race data from the WOBYC website. We can use the requests package along with BeautifulSoup to parse Sailwave race tables from a chosen URL, which can then be loaded into a Pandas `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://redacted/../redacted.htm'\n",
    "url = 'http://wobyc.com/wp-content/uploads/2020/08/Saturday-Fast-Handicap-August.htm'\n",
    "soup = BeautifulSoup(requests.get(url).text, \"lxml\")\n",
    "races = soup.find_all('table', attrs={'class': 'racetable'})\n",
    "races = [str(race) for race in races]\n",
    "anonymise(pd.read_html(races[0])[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then proceed to clean up the data. Note that we recompute the elapsed time from the corrected time instead of using the `'Elapsed'` column in the original data; this is to avoid problems with average lap races."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(races[0])[0].drop(['HelmName', 'CrewName', 'Boat'], axis=1)\n",
    "df.set_index('Rank', inplace=True)\n",
    "df = df[['Class', 'SailNo', 'PY', 'Corrected']]\n",
    "df.dropna(inplace=True)\n",
    "df['SailNo'] = df['SailNo'].astype('str')\n",
    "df['Class'] = df['Class'].astype('string')\n",
    "df['PY'] = df['PY'].astype('int')\n",
    "df['Corrected'] = pd.to_timedelta(df['Corrected']).dt.total_seconds()\n",
    "df['Elapsed'] = df['Corrected'] / df['PY'] * 1000\n",
    "anonymise(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the function `sailwave_to_df` to automatically load an html race table into a `DataFrame` and clean up the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sailwave_to_df(race, year):\n",
    "    try:\n",
    "        \"\"\"Converts a Sailwave table in html format to a pandas dataframe\"\"\"\n",
    "        df = pd.read_html(race, index_col='Rank')[0]\n",
    "        df = df[['Class', 'SailNo', 'PY', 'Corrected']]\n",
    "        df.dropna(inplace=True)\n",
    "        df['SailNo'] = df['SailNo'].astype('string')\n",
    "        df['Class'] = df['Class'].astype('string')\n",
    "        df['PY'] = df['PY'].astype('int')\n",
    "        df['Corrected'] = pd.to_timedelta(df['Corrected']).dt.total_seconds()\n",
    "        df['Elapsed'] = df['Corrected'] * df['PY'] / 1000\n",
    "        df['Year'] = year\n",
    "        return df\n",
    "    except KeyError:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define the function `scrape_sailwave` which scrapes a given URL for sailwave race tables and returns a list of races in `DataFrame` format using `sailwave_to_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_sailwave(url, year):\n",
    "    race_list = []\n",
    "    for link in BeautifulSoup(requests.get(url).text, \"lxml\").find_all('a'):\n",
    "        anchor = link.attrs[\"href\"] if \"href\" in link.attrs else ''\n",
    "        if anchor.endswith('htm'):\n",
    "            soup = BeautifulSoup(requests.get(anchor).text, \"lxml\")\n",
    "            tables = soup.find_all('table', attrs={'class': 'racetable'})\n",
    "            for race in tables:\n",
    "                try:\n",
    "                    temp = sailwave_to_df(str(race), year)\n",
    "                    race_list.append(temp)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "    return race_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use `scrape_sailwave` on a list of predefined URLs to obtain a list of races:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLs = [['http://redacted/../redacted1.htm', 2020],\n",
    "        ['http://redacted/../redacted2.htm', 2020],\n",
    "        ['http://redacted/../redacted3.htm', 2020]]\n",
    "URLs = [['http://wobyc.com/racing-results-winter-2019-2020/', 2020],\n",
    "        ['http://wobyc.com/racing-results-summer-2020/', 2020],\n",
    "        ['http://wobyc.com/oulton-week-2020/', 2020]]\n",
    "race_tables = []\n",
    "for [url, year] in URLs:\n",
    "    race_tables.extend(scrape_sailwave(url, year))\n",
    "anonymise(race_tables[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each race which the target boat sailed, a handicap is computed such that the XX2's corrected time is equal to the median corrected time for that race. Note that we use the median and not the mean; this is to ensure that the handicap is not disproportionately sensitive to outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handicaps_df = []\n",
    "for df in race_tables:\n",
    "    if target_sailnumber in df['SailNo'].values:\n",
    "        df_target = df.query('SailNo == @target_sailnumber')\n",
    "        df_remaining = df.query('SailNo != @target_sailnumber')\n",
    "        median_time = df_remaining['Corrected'].median()\n",
    "        target_time = df_target['Elapsed'].iloc[0]\n",
    "        handicap = 1000 * target_time / median_time\n",
    "        year = df['Year'].iloc[0]\n",
    "        handicaps_df.append([year, handicap])\n",
    "handicaps_df = pd.DataFrame(handicaps_df, columns=['Year', 'Handicap'])\n",
    "handicaps_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full race data has only been uploaded to the website since the start of 2020. However, for XX2 we can supplement these results with a pre-prepared Excel spreadsheet containing additional data from 2018 and 2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_sailnumber == 'XX2':\n",
    "    try:\n",
    "        xl = pd.ExcelFile('Catastrophe-Handicap.xlsx')\n",
    "        sheets = (xl.parse(name) for name in xl.sheet_names if name != 'Sheet1')\n",
    "        excel_data = (\n",
    "            [df['Elapsed.1'].loc[0] / (df.eval('Elapsed / Handicap').median()),\n",
    "             int(df['Year'].loc[0])] for df in sheets)\n",
    "        excel_df = pd.DataFrame(excel_data, columns=['Handicap', 'Year'])\n",
    "        handicaps_df = handicaps_df.append(excel_df, ignore_index=True)\n",
    "    except Exception:\n",
    "        print('Failed to load Excel file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then view some summary statistics about the estimated handicaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handicaps_df['Handicap'].describe().round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the mean is 12 points higher than the median. This is due to the mean's sensitivity to outliers; these outliers will be swewed towards higher handicaps for races where the target boat has performed particularly badly, perhaps due to a capsize or technical problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better idea of the distribution of handicaps we plot a boxplot of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_handicap = round(handicaps_df['Handicap'].median())\n",
    "fig1 = plt.figure()\n",
    "fig1.set_size_inches(3, 8)\n",
    "ax1 = sns.boxplot(y='Handicap', data=handicaps_df, showfliers=False)\n",
    "plot_title = 'Sail Number: ' + target_sailnumber + '\\n Handicap: ' + str(median_handicap)\n",
    "ax1.set(title=plot_title)\n",
    "ax1.yaxis.set_major_locator(ticker.MultipleLocator(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there's a fairly substantial variation between the upper and lower quartiles, indicating some uncertainty in the true handicap. Some of this variability can be explained by grouping the handicaps by year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handicaps_by_year = handicaps_df.groupby('Year')['Handicap']\n",
    "handicaps_by_year.describe().round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "fig2.set_size_inches(6, 10)\n",
    "ax2 = sns.boxplot(x='Year', y='Handicap', data=handicaps_df, showfliers=False)\n",
    "median_handicaps = handicaps_by_year.median().round().astype(int)\n",
    "plot_title = 'Sail Number: ' + target_sailnumber + '\\n Handicaps: '\n",
    "plot_title += ', '.join((str(median_handicaps.loc[i]) + ' (' + str(i) + ')'\n",
    "                        for i in median_handicaps.index))\n",
    "ax2.set(title=plot_title)\n",
    "ax2.yaxis.set_major_locator(ticker.MultipleLocator(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the grouped boxplots we observe that the handicap has undergone a drastic drop since 2018. 2018 was the first year the current owners sailed the boat, so it is reasonable to assume this drop in handicap corresponds to an increase in skill level as they've gained experience sailing it. We also observe that the handicap has much less variability in 2020, which increases our confidence in the estimated handicap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to consider the sample sizes for each year. The number of races used in the computation for each year is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handicaps_by_year.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that 2019 has significantly more races than 2020, and we can thus expect the 2019 handicap to be a more accurate prediction of the true handicap for that year. To ensure the handicap does not vary too significantly from year to year, we take the final handicap as the median handicap from the two most recent years, in this case 2019 and 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_handicap = round(handicaps_df.query('Year >= 2019')['Handicap'].median())\n",
    "print('The estimated handicap is', final_handicap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd0a861493f3e1c333d646ba33d2ebc703107f94dd88124d8d910e11711020c0a78",
   "display_name": "Python 3.7.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "9e2dcf00453500e07d4d170c6e7821af26c97d1f4c3809a7ae8c7973dccdd8bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}